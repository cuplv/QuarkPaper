\section{Introduction}
\label{sec:intro}

Large-scale web services and decentralized applications often rely on
geo-distributed state replication to meet their latency and availability
needs. An application's state is replicated asynchronously in such a
setting, meaning that operations are independently executed at each
replica, and updates are applied asynchronously at other replicas after a
possible network delay. Asynchronous execution complicates programming and
reasoning about distributed applications as it induces the possibility of
conflicting updates leading to non-convergence and application integrity
violations. Two basic approaches have been proposed to address this
problem. The first approach is to selectively strengthen the system
consistency to pre-empt the conflicting updates. The second is to redefine
the application state in terms of \emph{Replicated Data Types} (RDTs) that
are specially engineered to handle conflicting updates. Strengthening
system consistency necessarily entails inter-replica coordination,
therefore applications prefer to utilize RDTs as much as possible,
resorting to consistency strengthening only when it is necessary to maintain
application integrity. The common design principle guiding the development
of replicated data types is commutativity. The idea is that if the
replicated state is only updated by commutative operations, then updates
can be applied in any order and the replica states are still guaranteed to
converge. Indeed, there exist common usecases in web applications that can
be implemented using Commutative Replicated Data Types
(CRDTs)~\cite{crdts}. For instance, a video view counter on a streaming
application such as YouTube can be implemented as a Counter CRDT that
supports commutative increments.

In general, however, commutativity is not a common occurrence among
data types. Most common data type definitions come with at least a
pair of operations that do not commute. For instance an \C{add} and a
\C{remove} operations on a set do not commute if both are for the same
element.  Likewise two \C{insert} operations for the same position in
a list do not commute. Such non-commutative operations translate to
conflicting updates in a distributed setting, whose cumulative result
cannot be determined by the sequential specification of the data type
alone. To use a non-commutative data type in a replicated setting,
creative re-engineering of its internal representation and algorithms
is needed to turn it into a bonafide CRDT with a sensible distributed
semantics.
% In the case of set data type, that could involve changing the internal
% representation to maintain two sets -- a set containing the current
% elements and a \emph{tombstone} set that contains every element that
% has ever been deleted from the set. A \C{remove $k$} operation removes
% $k$ from the element set and adds it to the tombstone set, and an
% \C{insert $k$} operation adds $k$ to the element set only if it is not
% present in the tombstone set (i.e., only if $k$ was not previously
% deleted from the set). This results in a CRDT set called
% \emph{two-phase set} where an element once removed cannot be re-added. 
% A more complex re-engineering of the set data type could result in a set
% CRDT with a different (and arguably more useful) semantics.
% Sec.~\ref{sec:motivation} describes a \emph{remove-wins} CRDT set, which
% allows elements to be readded, but which prioritizes \C{remove}s over
% concurrent \C{insert}s. This transformation requires vector
% clocks~\cite{vectorclock} to keep track of casual ordering among
% \C{insert}s and \C{remove}s.
Indeed, most CRDTs have such carefully-crafted implementations that
rely on non-trivial technical devices to keep track of causal
dependencies and avoid or resolve conflicts. For instance, various
CRDT variants of the set abstract data type rely on \emph{vector
clocks} to identify conflicting \C{add}s and
\C{remove}s~\cite{zawirski-thesis, zhang}, Replicated Growable Array
(RGA) -- a CRDT for collaborative editing~\cite{rga} and JSON CRDT --
a CRDT variant of the JSON storage format, both use \emph{Lamport
timestamps}~\cite{rga, json-crdt}; and TreeDoc, another CRDT for
collaborative editing, makes use of \emph{dense linear
orders}~\cite{treedoc}. Such advanced implementations makes it hard to
reason about basic correctness properties of CRDTs, such as
convergence. Indeed, formal verification of \emph{strong eventual
consistency} (i.e., eventual convergence) for few of the
aforementioned CRDTs required considerable effort on behalf of
multiple authors who are experts in the field~\cite{kleppmann2017}.
The extraordinary effort and the expertise required to build CRDTs is
a deterrent towards using type-safe abstractions with strong
guarantees in distributed applications. To overcome this deterrent,
there is a need for an alternative approach that lets developers reuse
their sequential abstractions in a distributed setting with little to
no additional overhead of reasoning about their correctness properties
such as convergence.

% hinders the widespread adoption of replicated data
% types in software development.
In this paper we propose such an alternative approach to convergent
replicated data types.  
% The key distinguishing characteristic of
Our approach differs from the CRDT approach in
two fundamental ways. Firstly, we adopt a state-centric model of
replication with \emph{mergeability} of states as the defining
characteristic in contrast to CRDTs' operation-centric model
characterized by commutativity. Unlike commutativity, mergeability
does not require a full-scale re-engineering of the data type
definition. Instead, a data type only has to define a merge semantics
in form a \C{merge} function to reconcile concurrent versions of the
type in presence of their common ancestor version. Notably, \C{merge}
function is left completely unconstrained even as convergence is
guaranteed on the corresponding \emph{mergeable replicated data type}
(MRDT)~\cite{mrdt}. Such strong guarantees are possible due to the
simplicity of state-based reasoning relative to the operation- or
trace-based one. Note that state-centric model of replication has also
been adapted to CRDTs, but such state-based CRDTs require the
replicated state to be organized as a lattice to guarantee convergence
-- a restriction we eliminate in our setting. 

The second distinguishing aspect of our approach is the utilization of a
distributed runtime that orchestrates \emph{well-formed} distributed
executions that are guaranteed to converge. Note that it is easy to
construct a trivial runtime that guarantees convergence of all executions.
Such a runtime would make an extensive use of inter-replica coordination to
synchronize the execution of every operation and thus induce a
sequentially-consistent behavior. This would however defeat the purpose of
state replication as the latency incurred for synchronized execution of an
operation is prohibitively high, and the availability of the system during
the execution is correspondingly low. It is therefore important for a
distributed runtime of RDTs to not synchronize the execution of RDT
operations. Orchestrating a well-formed convergent execution without
impacting latency and availability may seem impossible due to the CAP
theorem~\cite{cap}, but it is not the case in fact. While CAP theorem does
rule out linearizability, it does not prohibit enforcing weaker consistency
constraints on distributed executions. In fact many CRDTs, including the
aforementioned \emph{remove-wins} set, implicitly assume \emph{causal
consistency}, which is weaker than linearizability but is stronger than the
default \emph{eventual consistency}. While causal consistency alone cannot
guarantee convergence, it sufficiently constrains the distributed execution
for the CRDT implementations to guarantee convergence. In this respect our
approach differs in the sense that (a). It identifies a novel set of
constraints on distributed execution that guarantee the convergence of an
MRDT \emph{regardless} of its merge semantics, and (b). It localizes those
constraints spatially and temporally into the runtime such that
per-operation latency and system-wide availability remain unaffected.
Sec.~\ref{sec:semantics} explains our runtime in detail. 

\paragraph{Contributions} The contributions of this paper are summarized
below:
\begin{itemize}
  \item We present a model of state replication for \emph{mergeable} data
  types, i.e., data types equipped with a \C{merge} function, and identify a
  structural well-formedness condition over distributed executions that is
  sufficient to guarantee their convergence. This is in contrast to
  existing models of replicated data types, where each type is obligated to
  prove its convergence.

  \item We formalize a distributed runtime called \quark that orchestrates
  well-formed distributed executions. We prove the correctness of \quark,
  and also demonstrate its \emph{progress} property, namely that no
  distributed execution would ever get ``stuck''. Besides the manual proofs
  for the theorems, we also provide the full formalization of the \quark
  system and its properties in Alloy~\cite{alloy} and Ivy~\cite{ivy}. The
  Ivy formalization of \quark has been automatically verified with help of
  Z3~\cite{z3}. To the best of our knowledge, this is the first time an SMT
  solver was used to verify the \emph{meta-theory} of a formal setup.

  \item We realize an implementation of \quark as a light-weight shim layer
  on top of Scylla -- an off-the-shelf distributed key-value
  store~\cite{scylla}. We do a thorough evaluation with a
    collaborative-editing benchmark to demonstrate that \quark has
    \emph{no} effect on the latency and availability of the system, while
    slightly increasing the time to convergence.
\end{itemize}

