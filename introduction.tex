\section{Introduction}
\label{sec:intro}

Large-scale web services and decentralized applications often rely on
geo-distributed state replication to meet their latency and availability
needs. An application's state is replicated asynchronously in such a
setting, meaning that operations are independently executed at each
replica, and updates are applied asynchronously at other replicas after a
possible network delay. Asynchronous execution complicates programming and
reasoning about distributed applications as it induces the possibility of
conflicting updates leading to non-convergence and application integrity
violations. Two basic approaches have been proposed to address this
problem. The first approach is to selectively strengthen the system
consistency to pre-empt the conflicting updates. The second is to redefine
the application state in terms of \emph{Replicated Data Types} (RDTs) that
are specially engineered to handle conflicting updates. Strengthening
system consistency necessarily entails inter-replica coordination,
therefore applications prefer to utilize RDTs as much as possible,
resorting to consistency strengthening only when it is necessary to maintain
application integrity. The common design principle guiding the development
of replicated data types is commutativity. The idea is that if the
replicated state is only updated by commutative operations, then updates
can be applied in any order and the replica states are still guaranteed to
converge. Indeed, there exist common usecases in web applications that can
be implemented using Commutative Replicated Data Types
(CRDTs)~\cite{crdts}. For instance, a video view counter on a streaming
application such as YouTube can be implemented as a Counter CRDT that
supports commutative increments.

In general, however, commutativity is not a common occurrence among
data types. Most common data type definitions come with at least a
pair of operations that do not commute. For instance an \C{add} and a
\C{remove} operations on a set do not commute if both are for the same
element.  Likewise two \C{insert} operations for the same position in
a list do not commute. Such non-commutative operations translate to
conflicting updates in a distributed setting, whose cumulative result
cannot be determined by the sequential specification of the data type
alone. To use a non-commutative data type in a replicated setting,
creative re-engineering of its internal representation and algorithms
is needed to turn it into a bonafide CRDT with a sensible distributed
semantics.
% In the case of set data type, that could involve changing the internal
% representation to maintain two sets -- a set containing the current
% elements and a \emph{tombstone} set that contains every element that
% has ever been deleted from the set. A \C{remove $k$} operation removes
% $k$ from the element set and adds it to the tombstone set, and an
% \C{insert $k$} operation adds $k$ to the element set only if it is not
% present in the tombstone set (i.e., only if $k$ was not previously
% deleted from the set). This results in a CRDT set called
% \emph{two-phase set} where an element once removed cannot be re-added. 
% A more complex re-engineering of the set data type could result in a set
% CRDT with a different (and arguably more useful) semantics.
% Sec.~\ref{sec:motivation} describes a \emph{remove-wins} CRDT set, which
% allows elements to be readded, but which prioritizes \C{remove}s over
% concurrent \C{insert}s. This transformation requires vector
% clocks~\cite{vectorclock} to keep track of casual ordering among
% \C{insert}s and \C{remove}s.
Indeed, most CRDTs have such carefully-crafted implementations that
rely on non-trivial technical devices to keep track of causal
dependencies and avoid or resolve conflicts. For instance, various
CRDT variants of the set abstract data type rely on \emph{vector
clocks} to identify conflicting \C{add}s and
\C{remove}s~\cite{zawirski-thesis, zhang}, Replicated Growable Array
(RGA) -- a CRDT for collaborative editing~\cite{rga}, and JSON CRDT --
a CRDT variant of the JSON storage format, both use \emph{Lamport
timestamps}~\cite{rga, json-crdt}; and TreeDoc, another CRDT for
collaborative editing, makes use of \emph{dense linear
orders}~\cite{treedoc}. Such advanced implementations makes it hard to
reason about basic correctness properties of CRDTs, such as
convergence. Indeed, formal verification of \emph{strong eventual
consistency} (i.e., eventual convergence) for few of the
aforementioned CRDTs required considerable effort on behalf of
multiple authors who are experts in the field~\cite{kleppmann2017}.
The extraordinary effort and the expertise required to build CRDTs is
a deterrent towards using type-safe abstractions with strong
guarantees in distributed applications. To overcome this deterrent,
there is a need for an alternative approach that lets developers reuse
their sequential abstractions in a distributed setting with little to
no additional overhead of reasoning about their correctness properties
such as convergence.

% hinders the widespread adoption of replicated data
% types in software development.
In this paper we propose such an alternative approach to convergent
replicated data types. The key distinguishing characteristic of our
approach is the utilization of a distributed runtime to orchestrate
\emph{well-formed} distributed executions that are guaranteed to
converge. We define well-formedness as a constraint over the
\emph{states} that arise during the execution as opposed to the
\emph{operations} that are involved in the execution. To allow for its
enforcement, we adopt a state-centric model of replication based on
version-controlled \emph{mergeable} states~\cite{mrdt} instead of an
operation-centric model based on commutative operations. Unlike
commutativity, mergeability does not require a data type definition to
be refactored to suit distributed execution. Instead, the type
definitions needs to be \emph{extended} with a \C{merge} function to
reconcile concurrent versions of the type in presence of their common
ancestor version. Notably, \C{merge} function is left completely
unconstrained. Consequently, programmer can chose any merge semantics
that make sense within the context of the data type's (sequential)
semantics without risking the loss of convergence. Such strong
guarantees are made possible by the simplicity of state-based
reasoning combined with the run-time enforcement of well-formedness. 

% combined with the simplicity
% of state-based reasoning. Note that state-centric model of
% replication has also been explored in the context of CRDTs. However,
% state-based CRDTs require the replicated state to be organized as a
% lattice -- a restriction we relax in our setting. 

Note that it is easy to construct a trivial runtime that guarantees
convergence of all executions.  Such a runtime would make an extensive
use of inter-replica coordination to synchronize the execution of
every operation and thus induce a sequentially-consistent behavior.
This would however defeat the purpose of state replication as the
latency incurred for synchronized execution of an operation is
prohibitively high, and the availability of the system during the
execution is correspondingly low. It is therefore important for a
distributed runtime of RDTs to not synchronize the execution of RDT
operations. Orchestrating a well-formed convergent execution without
impacting latency and availability may seem impossible due to the CAP
theorem~\cite{cap}, but it is not the case in fact. While CAP theorem
does rule out linearizability, it does not prohibit enforcing weaker
consistency constraints on distributed executions. Our approach
exploits this observation by (\rom{1}). Identifying a novel set of
constraints on distributed executions that guarantee their
convergence, and (\rom{2}). Localizing such constraints on
(asynchronously executed) state merges such that per-operation latency
and system-wide availability remain unaffected.
Sec.~\ref{sec:concrete-sem} explains our runtime in detail.

% In fact many CRDTs,
% including the aforementioned \emph{remove-wins} set, implicitly assume
% \emph{causal consistency}, which is weaker than linearizability but is
% stronger than the default \emph{eventual consistency}. While causal
% consistency alone cannot guarantee convergence, it sufficiently
% constrains the distributed execution for the CRDT implementations to
% guarantee convergence. In this respect our approach differs in the
% sense that  

\paragraph{Contributions} The contributions of this paper are summarized
below:
\begin{itemize}
  \item We present a runtime-assisted approach to state replication
    that sufficiently constrains distributed executions so as to
    guarantee the convergence of replicated data types. This is in
    contrast to the existing models of replication, where each type is
    obligated to prove its convergence.

  \item We formalize the aforementioned constraints in the context of
    a an abstract machine (named \quark) that manifests distributed
    executions as version history graphs (similar to Git~\cite{git}).
    We prove the \emph{convergence} and \emph{progress} properties of
    the \quark abstract machine that together guarantee its soundness.
    The formalization has been mechanized in Ivy~\cite{ivy} and
    \emph{automatically} verified with help of Z3~\cite{z3}. To the
    best of our knowledge, this is the first time an SMT solver was
    used to verify the \emph{meta-theory} of a formal system.

  \item We formalize \quark distributed machine that implements the
    semantics of \quark abstract machine in the context of an
    asynchronous distributed system. The formalization addresses
    several practical concerns of distribution and serves as a
    blueprint for an efficient implementation.

  \item We describe an implementation of \quark as a light-weight shim
    layer on top of Scylla -- an off-the-shelf distributed key-value
    store~\cite{scylla}. We evaluate the implementation on a
    collaborative-editing benchmark to demonstrate novel tradeoffs
    presented by our approach.
\end{itemize}

